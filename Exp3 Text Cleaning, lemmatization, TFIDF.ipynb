{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eH7ZOFAhS-bj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sc7nY1_VudY9"
   },
   "outputs": [],
   "source": [
    "path_df = \"News_dataset.pickle\"\n",
    "\n",
    "with open(path_df, 'rb') as data:\n",
    "    data = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "w8Yd6J3ews5h",
    "outputId": "f0886078-e1c6-44c3-942a-9264225ba0cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name                                            Content  Category  \\\n",
       "0   001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1   002.txt  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2   003.txt  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3   004.txt  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4   005.txt  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "\n",
       "  Complete_Filename  id  News_length  \n",
       "0  001.txt-business   1         2569  \n",
       "1  002.txt-business   1         2257  \n",
       "2  003.txt-business   1         1557  \n",
       "3  004.txt-business   1         2421  \n",
       "4  005.txt-business   1         1575  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "yPVrmIpGtF1D",
    "outputId": "4347f1d5-42a5-4060-d7ed-4448074fa836"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dollar gains on Greenspan speech\\r\\n\\r\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\r\\n\\r\\nAnd Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman\\'s taking a much more sanguine view on the current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\\r\\n\\r\\nWorries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged to the dollar and the US currency\\'s sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.loc[1]['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plFDixlbAk9A"
   },
   "source": [
    "## 1.  Text cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Ad sales boost Time Warner profit  Quarterly p...\n",
       "1       Dollar gains on Greenspan speech  The dollar h...\n",
       "2       Yukos unit buyer faces loan claim  The owners ...\n",
       "3       High fuel prices hit BA's profits  British Air...\n",
       "4       Pernod takeover talk lifts Domecq  Shares in U...\n",
       "                              ...                        \n",
       "2220    BT program to beat dialler scams  BT is introd...\n",
       "2221    Spam e-mails tempt net shoppers  Computer user...\n",
       "2222    Be careful how you code  A new European direct...\n",
       "2223    US cyber security chief resigns  The man makin...\n",
       "2224    Losing yourself in online gaming  Online role ...\n",
       "Name: Clean_Content, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clean_Content']=data['Content'].apply(lambda x: x.replace(\"\\r\",\" \"))\n",
    "data['Clean_Content']=data['Clean_Content'].apply(lambda x: x.replace(\"\\n\",\" \"))\n",
    "data['Clean_Content']=data['Clean_Content'].apply(lambda x: x.replace(\"   \",\" \"))\n",
    "data['Clean_Content']=data['Clean_Content'].apply(lambda x: x.replace('\"',''))\n",
    "data['Clean_Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dollar gains on Greenspan speech  The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.  And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time, said Robert Sinche, head of currency strategy at Bank of America in New York. He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.  Worries about the deficit concerns about China do, however, remain. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing's policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the time is ripe for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve's decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1]['Clean_Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Clean_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2257</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1557</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2421</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1575</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name                                            Content  Category  \\\n",
       "0   001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1   002.txt  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2   003.txt  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3   004.txt  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4   005.txt  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "\n",
       "  Complete_Filename  id  News_length  \\\n",
       "0  001.txt-business   1         2569   \n",
       "1  002.txt-business   1         2257   \n",
       "2  003.txt-business   1         1557   \n",
       "3  004.txt-business   1         2421   \n",
       "4  005.txt-business   1         1575   \n",
       "\n",
       "                                       Clean_Content  \n",
       "0  Ad sales boost Time Warner profit  Quarterly p...  \n",
       "1  Dollar gains on Greenspan speech  The dollar h...  \n",
       "2  Yukos unit buyer faces loan claim  The owners ...  \n",
       "3  High fuel prices hit BA's profits  British Air...  \n",
       "4  Pernod takeover talk lifts Domecq  Shares in U...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ad sales boost time warner profit  quarterly p...\n",
       "1       dollar gains on greenspan speech  the dollar h...\n",
       "2       yukos unit buyer faces loan claim  the owners ...\n",
       "3       high fuel prices hit ba's profits  british air...\n",
       "4       pernod takeover talk lifts domecq  shares in u...\n",
       "                              ...                        \n",
       "2220    bt program to beat dialler scams  bt is introd...\n",
       "2221    spam e-mails tempt net shoppers  computer user...\n",
       "2222    be careful how you code  a new european direct...\n",
       "2223    us cyber security chief resigns  the man makin...\n",
       "2224    losing yourself in online gaming  online role ...\n",
       "Name: Clean_Content, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clean_Content']=data['Clean_Content'].apply(lambda x: x.lower())\n",
    "data['Clean_Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Clean_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2257</td>\n",
       "      <td>dollar gains greenspan speech dollar hit highe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1557</td>\n",
       "      <td>yukos unit buyer faces loan claim owners embat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2421</td>\n",
       "      <td>high fuel prices hit ba 's profits british air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1575</td>\n",
       "      <td>pernod takeover talk lifts domecq shares uk dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>397.txt</td>\n",
       "      <td>BT program to beat dialler scams\\r\\n\\r\\nBT is ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>397.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2526</td>\n",
       "      <td>bt program beat dialler scams bt introducing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>398.txt</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...</td>\n",
       "      <td>tech</td>\n",
       "      <td>398.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>spam e-mails tempt net shoppers computer users...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>399.txt</td>\n",
       "      <td>Be careful how you code\\r\\n\\r\\nA new European ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>399.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>6297</td>\n",
       "      <td>careful code new european directive could put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>400.txt</td>\n",
       "      <td>US cyber security chief resigns\\r\\n\\r\\nThe man...</td>\n",
       "      <td>tech</td>\n",
       "      <td>400.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2323</td>\n",
       "      <td>us cyber security chief resigns man making sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>401.txt</td>\n",
       "      <td>Losing yourself in online gaming\\r\\n\\r\\nOnline...</td>\n",
       "      <td>tech</td>\n",
       "      <td>401.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>16248</td>\n",
       "      <td>losing online gaming online role playing games...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_Name                                            Content  Category  \\\n",
       "0      001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1      002.txt  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2      003.txt  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3      004.txt  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4      005.txt  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "...        ...                                                ...       ...   \n",
       "2220   397.txt  BT program to beat dialler scams\\r\\n\\r\\nBT is ...      tech   \n",
       "2221   398.txt  Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...      tech   \n",
       "2222   399.txt  Be careful how you code\\r\\n\\r\\nA new European ...      tech   \n",
       "2223   400.txt  US cyber security chief resigns\\r\\n\\r\\nThe man...      tech   \n",
       "2224   401.txt  Losing yourself in online gaming\\r\\n\\r\\nOnline...      tech   \n",
       "\n",
       "     Complete_Filename  id  News_length  \\\n",
       "0     001.txt-business   1         2569   \n",
       "1     002.txt-business   1         2257   \n",
       "2     003.txt-business   1         1557   \n",
       "3     004.txt-business   1         2421   \n",
       "4     005.txt-business   1         1575   \n",
       "...                ...  ..          ...   \n",
       "2220      397.txt-tech   1         2526   \n",
       "2221      398.txt-tech   1         2294   \n",
       "2222      399.txt-tech   1         6297   \n",
       "2223      400.txt-tech   1         2323   \n",
       "2224      401.txt-tech   1        16248   \n",
       "\n",
       "                                          Clean_Content  \n",
       "0     ad sales boost time warner profit quarterly pr...  \n",
       "1     dollar gains greenspan speech dollar hit highe...  \n",
       "2     yukos unit buyer faces loan claim owners embat...  \n",
       "3     high fuel prices hit ba 's profits british air...  \n",
       "4     pernod takeover talk lifts domecq shares uk dr...  \n",
       "...                                                 ...  \n",
       "2220  bt program beat dialler scams bt introducing t...  \n",
       "2221  spam e-mails tempt net shoppers computer users...  \n",
       "2222  careful code new european directive could put ...  \n",
       "2223  us cyber security chief resigns man making sur...  \n",
       "2224  losing online gaming online role playing games...  \n",
       "\n",
       "[2225 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_punct=set(string.punctuation)\n",
    "stop_wards=set(stopwords.words('English'))\n",
    "\n",
    "def cleaning_text(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    filtered_text=[word for word in tokens if word.lower() not in stop_wards and word not in exclude_punct]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "data['Clean_Content']=data['Clean_Content'].apply(cleaning_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dollar gains on Greenspan speech\\r\\n\\r\\nThe dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\\r\\n\\r\\nAnd Alan Greenspan highlighted the US government\\'s willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan\\'s speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman\\'s taking a much more sanguine view on the current account deficit than he\\'s taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He\\'s taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\\r\\n\\r\\nWorries about the deficit concerns about China do, however, remain. China\\'s currency remains pegged to the dollar and the US currency\\'s sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing\\'s policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve\\'s decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US\\'s yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Content'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dollar gains greenspan speech dollar hit highest level euro almost three months federal reserve head said us trade deficit set stabilise alan greenspan highlighted us government 's willingness curb spending rising household savings factors may help reduce late trading new york dollar reached 1.2871 euro 1.2974 thursday market concerns deficit hit greenback recent months friday federal reserve chairman mr greenspan 's speech london ahead meeting g7 finance ministers sent dollar higher earlier tumbled back worse-than-expected us jobs data think chairman 's taking much sanguine view current account deficit 's taken time said robert sinche head currency strategy bank america new york 's taking longer-term view laying set conditions current account deficit improve year next worries deficit concerns china however remain china 's currency remains pegged dollar us currency 's sharp falls recent months therefore made chinese export prices highly competitive calls shift beijing 's policy fallen deaf ears despite recent comments major chinese newspaper time ripe loosening peg g7 meeting thought unlikely produce meaningful movement chinese policy meantime us federal reserve 's decision 2 february boost interest rates quarter point sixth move many months opened differential european rates half-point window believe could enough keep us assets looking attractive could help prop dollar recent falls partly result big budget deficits well us 's yawning current account gap need funded buying us bonds assets foreign firms governments white house announce budget monday many commentators believe deficit remain close half trillion dollars\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clean_Content'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dollar gains greenspan speech dollar hit highest level euro almost three months federal reserve head said us trade deficit set stabilise alan greenspan highlighted us government  willingness curb spending rising household savings factors may help reduce late trading new york dollar reached 1.2871 euro 1.2974 thursday market concerns deficit hit greenback recent months friday federal reserve chairman mr greenspan  speech london ahead meeting g7 finance ministers sent dollar higher earlier tumbled back worse-than-expected us jobs data think chairman  taking much sanguine view current account deficit  taken time said robert sinche head currency strategy bank america new york  taking longer-term view laying set conditions current account deficit improve year next worries deficit concerns china however remain china  currency remains pegged dollar us currency  sharp falls recent months therefore made chinese export prices highly competitive calls shift beijing  policy fallen deaf ears despite recent comments major chinese newspaper time ripe loosening peg g7 meeting thought unlikely produce meaningful movement chinese policy meantime us federal reserve  decision 2 february boost interest rates quarter point sixth move many months opened differential european rates half-point window believe could enough keep us assets looking attractive could help prop dollar recent falls partly result big budget deficits well us  yawning current account gap need funded buying us bonds assets foreign firms governments white house announce budget monday many commentators believe deficit remain close half trillion dollars'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clean_Content']=data['Clean_Content'].apply(lambda x: x.replace(\"'s\",\"\"))\n",
    "data['Clean_Content'].loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCYxU3bGOBab"
   },
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMB0BmTl11B9",
    "outputId": "4ef05607-d2e9-417e-ef11-02f307118ee4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0WaMcetLvke"
   },
   "source": [
    "#### 1st method lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Clean_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2257</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1557</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2421</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1575</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>397.txt</td>\n",
       "      <td>BT program to beat dialler scams\\r\\n\\r\\nBT is ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>397.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2526</td>\n",
       "      <td>bt program beat dialler scam bt introducing tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>398.txt</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...</td>\n",
       "      <td>tech</td>\n",
       "      <td>398.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "      <td>spam e-mail tempt net shopper computer user ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>399.txt</td>\n",
       "      <td>Be careful how you code\\r\\n\\r\\nA new European ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>399.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>6297</td>\n",
       "      <td>careful code new european directive could put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>400.txt</td>\n",
       "      <td>US cyber security chief resigns\\r\\n\\r\\nThe man...</td>\n",
       "      <td>tech</td>\n",
       "      <td>400.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2323</td>\n",
       "      <td>u cyber security chief resigns man making sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>401.txt</td>\n",
       "      <td>Losing yourself in online gaming\\r\\n\\r\\nOnline...</td>\n",
       "      <td>tech</td>\n",
       "      <td>401.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>16248</td>\n",
       "      <td>losing online gaming online role playing game ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_Name                                            Content  Category  \\\n",
       "0      001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1      002.txt  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2      003.txt  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3      004.txt  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4      005.txt  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "...        ...                                                ...       ...   \n",
       "2220   397.txt  BT program to beat dialler scams\\r\\n\\r\\nBT is ...      tech   \n",
       "2221   398.txt  Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...      tech   \n",
       "2222   399.txt  Be careful how you code\\r\\n\\r\\nA new European ...      tech   \n",
       "2223   400.txt  US cyber security chief resigns\\r\\n\\r\\nThe man...      tech   \n",
       "2224   401.txt  Losing yourself in online gaming\\r\\n\\r\\nOnline...      tech   \n",
       "\n",
       "     Complete_Filename  id  News_length  \\\n",
       "0     001.txt-business   1         2569   \n",
       "1     002.txt-business   1         2257   \n",
       "2     003.txt-business   1         1557   \n",
       "3     004.txt-business   1         2421   \n",
       "4     005.txt-business   1         1575   \n",
       "...                ...  ..          ...   \n",
       "2220      397.txt-tech   1         2526   \n",
       "2221      398.txt-tech   1         2294   \n",
       "2222      399.txt-tech   1         6297   \n",
       "2223      400.txt-tech   1         2323   \n",
       "2224      401.txt-tech   1        16248   \n",
       "\n",
       "                                          Clean_Content  \n",
       "0     ad sale boost time warner profit quarterly pro...  \n",
       "1     dollar gain greenspan speech dollar hit highes...  \n",
       "2     yukos unit buyer face loan claim owner embattl...  \n",
       "3     high fuel price hit ba profit british airway b...  \n",
       "4     pernod takeover talk lift domecq share uk drin...  \n",
       "...                                                 ...  \n",
       "2220  bt program beat dialler scam bt introducing tw...  \n",
       "2221  spam e-mail tempt net shopper computer user ac...  \n",
       "2222  careful code new european directive could put ...  \n",
       "2223  u cyber security chief resigns man making sure...  \n",
       "2224  losing online gaming online role playing game ...  \n",
       "\n",
       "[2225 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    lemma=WordNetLemmatizer()\n",
    "    lemma_text=[lemma.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemma_text)\n",
    "\n",
    "data['Clean_Content']=data['Clean_Content'].apply(lemmatize_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Clean_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>dollar gain greenspan speech dollar hit highes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams\\r\\n\\r\\nBT is ...</td>\n",
       "      <td>bt program beat dialler scam bt introducing tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...</td>\n",
       "      <td>spam e-mail tempt net shopper computer user ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code\\r\\n\\r\\nA new European ...</td>\n",
       "      <td>careful code new european directive could put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns\\r\\n\\r\\nThe man...</td>\n",
       "      <td>u cyber security chief resigns man making sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming\\r\\n\\r\\nOnline...</td>\n",
       "      <td>losing online gaming online role playing game ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content  \\\n",
       "0     Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...   \n",
       "1     Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...   \n",
       "2     Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...   \n",
       "3     High fuel prices hit BA's profits\\r\\n\\r\\nBriti...   \n",
       "4     Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...   \n",
       "...                                                 ...   \n",
       "2220  BT program to beat dialler scams\\r\\n\\r\\nBT is ...   \n",
       "2221  Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...   \n",
       "2222  Be careful how you code\\r\\n\\r\\nA new European ...   \n",
       "2223  US cyber security chief resigns\\r\\n\\r\\nThe man...   \n",
       "2224  Losing yourself in online gaming\\r\\n\\r\\nOnline...   \n",
       "\n",
       "                                          Clean_Content  \n",
       "0     ad sale boost time warner profit quarterly pro...  \n",
       "1     dollar gain greenspan speech dollar hit highes...  \n",
       "2     yukos unit buyer face loan claim owner embattl...  \n",
       "3     high fuel price hit ba profit british airway b...  \n",
       "4     pernod takeover talk lift domecq share uk drin...  \n",
       "...                                                 ...  \n",
       "2220  bt program beat dialler scam bt introducing tw...  \n",
       "2221  spam e-mail tempt net shopper computer user ac...  \n",
       "2222  careful code new european directive could put ...  \n",
       "2223  u cyber security chief resigns man making sure...  \n",
       "2224  losing online gaming online role playing game ...  \n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Content','Clean_Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dollar gains on Greenspan speech\r\n",
      "\r\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\r\n",
      "\r\n",
      "And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings as factors which may help to reduce it. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. Market concerns about the deficit has hit the greenback in recent months. On Friday, Federal Reserve chairman Mr Greenspan's speech in London ahead of the meeting of G7 finance ministers sent the dollar higher after it had earlier tumbled on the back of worse-than-expected US jobs data. \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"He's taking a longer-term view, laying out a set of conditions under which the current account deficit can improve this year and next.\"\r\n",
      "\r\n",
      "Worries about the deficit concerns about China do, however, remain. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive. But calls for a shift in Beijing's policy have fallen on deaf ears, despite recent comments in a major Chinese newspaper that the \"time is ripe\" for a loosening of the peg. The G7 meeting is thought unlikely to produce any meaningful movement in Chinese policy. In the meantime, the US Federal Reserve's decision on 2 February to boost interest rates by a quarter of a point - the sixth such move in as many months - has opened up a differential with European rates. The half-point window, some believe, could be enough to keep US assets looking more attractive, and could help prop up the dollar. The recent falls have partly been the result of big budget deficits, as well as the US's yawning current account gap, both of which need to be funded by the buying of US bonds and assets by foreign firms and governments. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\n",
      "=====================================================After Cleaning===================================================\n",
      "dollar gains greenspan speech dollar hit highest level euro almost three months federal reserve head said us trade deficit set stabilise alan greenspan highlighted us government willingness curb spending rising household savings factors may help reduce late trading new york dollar reached 1.2871 euro 1.2974 thursday market concerns deficit hit greenback recent months friday federal reserve chairman mr greenspan speech london ahead meeting g7 finance ministers sent dollar higher earlier tumbled back worse-than-expected us jobs data think chairman taking much sanguine view current account deficit taken time said robert sinche head currency strategy bank america new york taking longer-term view laying set conditions current account deficit improve year next worries deficit concerns china however remain china currency remains pegged dollar us currency sharp falls recent months therefore made chinese export prices highly competitive calls shift beijing policy fallen deaf ears despite recent comments major chinese newspaper time ripe loosening peg g7 meeting thought unlikely produce meaningful movement chinese policy meantime us federal reserve decision 2 february boost interest rates quarter point sixth move many months opened differential european rates half-point window believe could enough keep us assets looking attractive could help prop dollar recent falls partly result big budget deficits well us yawning current account gap need funded buying us bonds assets foreign firms governments white house announce budget monday many commentators believe deficit remain close half trillion dollars\n"
     ]
    }
   ],
   "source": [
    "print(data['Content'].loc[1])\n",
    "print(\"=====================================================After Cleaning===================================================\")\n",
    "print(data['Clean_Content'].loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7aCUb1qz36GO"
   },
   "outputs": [],
   "source": [
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nrows = len(data)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "df['Content_Parsed_5'] = lemmatized_text_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aCAu8N2FjWl",
    "outputId": "d833f41c-74e8-4251-eb5d-6462f6c0170f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ad sales boost time warner profit quarterly pr...\n",
       "1       dollar gain on greenspan speech the dollar hav...\n",
       "2       yukos unit buyer face loan claim the owners of...\n",
       "3       high fuel price hit ba profit british airways ...\n",
       "4       pernod takeover talk lift domecq share in uk d...\n",
       "                              ...                        \n",
       "2220    bt program to beat dialler scam bt be introduc...\n",
       "2221    spam e-mail tempt net shoppers computer users ...\n",
       "2222    be careful how you code a new european directi...\n",
       "2223    us cyber security chief resign the man make su...\n",
       "2224    lose yourself in online game online role play ...\n",
       "Name: Content_Parsed_5, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content_Parsed_5']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8_fCLACL8uk"
   },
   "source": [
    "#### 2nd method for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XCLczhk6FzrI"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    lemmatized_text = lemmatize_sentence(df.loc[row]['Content_Parsed_4'])\n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "df['Content_Parsed_5'] = lemmatized_text_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zc5sd5UXMMnN",
    "outputId": "dede6da4-439b-4db8-98e3-91aa1854fc57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ad sale boost time warner profit quarterly pro...\n",
       "1       dollar gain on greenspan speech the dollar hav...\n",
       "2       yukos unit buyer face loan claim the owner of ...\n",
       "3       high fuel price hit ba profit british airway h...\n",
       "4       pernod takeover talk lift domecq share in uk d...\n",
       "                              ...                        \n",
       "2220    bt program to beat dialler scam bt be introduc...\n",
       "2221    spam e-mails tempt net shopper computer user a...\n",
       "2222    be careful how you code a new european directi...\n",
       "2223    us cyber security chief resign the man make su...\n",
       "2224    lose yourself in online gaming online role pla...\n",
       "Name: Content_Parsed_5, Length: 2225, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content_Parsed_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA9rYSi6rceS"
   },
   "source": [
    "### b) Use any 1 method for stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFzGE0OldTMu",
    "outputId": "05859efb-d9a3-4576-a1c8-01b4a386dec3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/dipali/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bumHuGZYeQX0"
   },
   "outputs": [],
   "source": [
    "#Removing stop words\n",
    "\n",
    "stop_words = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlMwHosAri_I"
   },
   "source": [
    "#### 1st Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EevBUtPPn1hR",
    "outputId": "5fa75e84-d6a5-4aae-992f-c42486523955"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4042/2995545048.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "\n",
    "for stop_word in stop_words:\n",
    "\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "AHNkwlBDrlJI",
    "outputId": "e23673f3-14ec-4047-9030-adc242782043"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escape recession japan economy teeter   brink   technical recession   three month  september figure show revised figure indicate growth   01 % -   similar-sized contraction   previous quarter   annual basis  data suggest annual growth   02 % suggest  much  hesitant recovery   previously  think  common technical definition   recession  two successive quarter  negative growth  government  keen  play   worrying implication   data  maintain  view  japan economy remain   minor adjustment phase   upward climb    monitor development carefully say economy minister heizo takenaka    face   strengthen yen make export less competitive  indication  weaken economic condition ahead observer  less sanguine  paint  picture   recovery much patchy  previously think say paul sheard economist  lehman brother  tokyo improvement   job market apparently  yet  fee   domestic demand  private consumption   02 %   third quarter'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge00Y4vStKKb"
   },
   "source": [
    "#### 2nd Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PzbC4XFWrwmA"
   },
   "outputs": [],
   "source": [
    "stop_list_final=[]\n",
    "nrows = len(df)\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing no stop words\n",
    "    stop_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['Content_Parsed_5']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to remove stopwords\n",
    "    for word in text_words:\n",
    "        if (word not in stopwords_english): \n",
    "          stop_list.append(word)\n",
    "        \n",
    "    # Join the list\n",
    "    stop_text = \" \".join(stop_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    stop_list_final.append(stop_text)\n",
    "\n",
    "df['Content_Parsed_6'] = stop_list_final   \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "eBftZQFNiL-J",
    "outputId": "ae05104d-a244-4cdc-dc99-49c81961b8b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japan narrowly escape recession japan economy teeter brink technical recession three month september figure show revised figure indicate growth 01 % - similar-sized contraction previous quarter annual basis data suggest annual growth 02 % suggest much hesitant recovery previously think common technical definition recession two successive quarter negative growth government keen play worrying implication data maintain view japan economy remain minor adjustment phase upward climb monitor development carefully say economy minister heizo takenaka face strengthen yen make export less competitive indication weaken economic condition ahead observer less sanguine paint picture recovery much patchy previously think say paul sheard economist lehman brother tokyo improvement job market apparently yet fee domestic demand private consumption 02 % third quarter'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5]['Content_Parsed_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "MSKIlkjv_Ggi",
    "outputId": "99943615-62cc-46f3-d1b5-1d13e1638fed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "      <th>Content_Parsed_1</th>\n",
       "      <th>Content_Parsed_2</th>\n",
       "      <th>Content_Parsed_3</th>\n",
       "      <th>Content_Parsed_4</th>\n",
       "      <th>Content_Parsed_5</th>\n",
       "      <th>Content_Parsed_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "      <td>Ad sales boost Time Warner profit Quarterly pr...</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>ad sales boost time warner profit quarterly pr...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name                                            Content  Category  \\\n",
       "0   001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "\n",
       "  Complete_Filename  id  News_length  \\\n",
       "0  001.txt-business   1         2569   \n",
       "\n",
       "                                    Content_Parsed_1  \\\n",
       "0  Ad sales boost Time Warner profit Quarterly pr...   \n",
       "\n",
       "                                    Content_Parsed_2  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "\n",
       "                                    Content_Parsed_3  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "\n",
       "                                    Content_Parsed_4  \\\n",
       "0  ad sales boost time warner profit quarterly pr...   \n",
       "\n",
       "                                    Content_Parsed_5  \\\n",
       "0  ad sale boost time warner profit quarterly pro...   \n",
       "\n",
       "                                    Content_Parsed_6  \n",
       "0  ad sale boost time warner profit quarterly pro...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking data\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1Z_AUcVC_-7p"
   },
   "outputs": [],
   "source": [
    "#Removing the old content_parsed columns\n",
    "\n",
    "list_columns = [\"File_Name\", \"Category\", \"Complete_Filename\", \"Content\", \"Content_Parsed_6\"]\n",
    "df = df[list_columns]\n",
    "\n",
    "df = df.rename(columns={'Content_Parsed_6': 'Content_Parsed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T617bG_sARfk",
    "outputId": "3761a2fe-1596-4418-a57e-a3c583dc3741"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category Complete_Filename  \\\n",
       "0   001.txt  business  001.txt-business   \n",
       "1   002.txt  business  002.txt-business   \n",
       "2   003.txt  business  003.txt-business   \n",
       "3   004.txt  business  004.txt-business   \n",
       "4   005.txt  business  005.txt-business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...   \n",
       "1  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...   \n",
       "2  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...   \n",
       "3  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...   \n",
       "4  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...   \n",
       "\n",
       "                                      Content_Parsed  \n",
       "0  ad sale boost time warner profit quarterly pro...  \n",
       "1  dollar gain greenspan speech dollar hit high l...  \n",
       "2  yukos unit buyer face loan claim owner embattl...  \n",
       "3  high fuel price hit ba profit british airway b...  \n",
       "4  pernod takeover talk lift domecq share uk drin...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qReJ8BdgArQK"
   },
   "source": [
    "## 2. Label coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NQkPBjSpATxK"
   },
   "outputs": [],
   "source": [
    "#Generating new column for Category codes\n",
    "\n",
    "category_codes = {\n",
    "    'business': 0,\n",
    "    'entertainment': 1,\n",
    "    'politics': 2,\n",
    "    'sport': 3,\n",
    "    'tech': 4\n",
    "}\n",
    "\n",
    "# Category mapping\n",
    "df['Category_Code'] = df['Category']\n",
    "df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oAABDQ5XCEkO",
    "outputId": "08d41e5b-78db-49f1-ee4f-78535af6eeba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>Content</th>\n",
       "      <th>Content_Parsed</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category Complete_Filename  \\\n",
       "0   001.txt  business  001.txt-business   \n",
       "1   002.txt  business  002.txt-business   \n",
       "2   003.txt  business  003.txt-business   \n",
       "3   004.txt  business  004.txt-business   \n",
       "4   005.txt  business  005.txt-business   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...   \n",
       "1  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...   \n",
       "2  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...   \n",
       "3  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...   \n",
       "4  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...   \n",
       "\n",
       "                                      Content_Parsed  Category_Code  \n",
       "0  ad sale boost time warner profit quarterly pro...              0  \n",
       "1  dollar gain greenspan speech dollar hit high l...              0  \n",
       "2  yukos unit buyer face loan claim owner embattl...              0  \n",
       "3  high fuel price hit ba profit british airway b...              0  \n",
       "4  pernod takeover talk lift domecq share uk drin...              0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-HGGfsBCtHl"
   },
   "source": [
    "## 3. Train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "X2txuKkYCHh3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Content_Parsed'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgoVG5EdC0Mk"
   },
   "source": [
    "## 4. Text representation\n",
    "\n",
    "TF-IDF Vectors\n",
    "\n",
    "unigrams & bigrams corresponding to a particular category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "epbPtDKRCw9O"
   },
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AsXYdtChD21W",
    "outputId": "b9786651-9678-4aa8-c34b-b82db609e08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6vdy_FDD6VK",
    "outputId": "69a14810-0b19-4a37-a91d-80a9807645fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business' category:\n",
      "  . Most correlated unigrams:\n",
      ". price\n",
      ". market\n",
      ". economy\n",
      ". growth\n",
      ". bank\n",
      "  . Most correlated bigrams:\n",
      ". last year\n",
      ". year old\n",
      "\n",
      "# 'entertainment' category:\n",
      "  . Most correlated unigrams:\n",
      ". best\n",
      ". music\n",
      ". star\n",
      ". award\n",
      ". film\n",
      "  . Most correlated bigrams:\n",
      ". mr blair\n",
      ". prime minister\n",
      "\n",
      "# 'politics' category:\n",
      "  . Most correlated unigrams:\n",
      ". blair\n",
      ". party\n",
      ". election\n",
      ". tory\n",
      ". labour\n",
      "  . Most correlated bigrams:\n",
      ". prime minister\n",
      ". mr blair\n",
      "\n",
      "# 'sport' category:\n",
      "  . Most correlated unigrams:\n",
      ". side\n",
      ". player\n",
      ". team\n",
      ". game\n",
      ". match\n",
      "  . Most correlated bigrams:\n",
      ". say mr\n",
      ". year old\n",
      "\n",
      "# 'tech' category:\n",
      "  . Most correlated unigrams:\n",
      ". mobile\n",
      ". software\n",
      ". technology\n",
      ". computer\n",
      ". user\n",
      "  . Most correlated bigrams:\n",
      ". year old\n",
      ". say mr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names_out())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7JOkhhhEnV_",
    "outputId": "f339bfdd-fe3d-4bec-f9c5-7d991322e381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tell bbc', 'last year', 'mr blair', 'prime minister', 'year old', 'say mr']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQAtmDipneir"
   },
   "source": [
    "Unigrams are more relevnat to the category as compared with bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LpRcdYL8IhlG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# X_train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(X_train, output)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# X_test    \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/Pickles/X_test.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m output:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# X_train\n",
    "with open('X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# df\n",
    "with open('df.pickle', 'wb') as output:\n",
    "    pickle.dump(df, output)\n",
    "    \n",
    "# features_train\n",
    "with open('features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('/content/drive/My Drive/Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('/content/drive/My Drive/Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-Course-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
